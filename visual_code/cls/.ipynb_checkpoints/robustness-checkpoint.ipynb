{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8541ef08-16b6-425c-b8b1-dc97026730f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import _init_path\n",
    "from torch.autograd import Variable\n",
    "from cls.data import ModelNet40, ScanObjectNN\n",
    "from util import cal_loss\n",
    "\n",
    "from cls.model_mixup import PointNet, DGCNN, Pointnet2_MSG\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Point Cloud Recognition')\n",
    "parser.add_argument('--model', type=str, default='dgcnn', metavar='N',\n",
    "                    choices=['pointnet', 'dgcnn', 'pointnet2_MSG'],\n",
    "                    help='Model to use, [pointnet, dgcnn]')\n",
    "parser.add_argument('--data', type=str, default='MN40', metavar='N',\n",
    "                    choices=['MN40', 'SONN_EASY', 'SONN_HARD'])\n",
    "parser.add_argument('--batch_size', type=int, default=16, metavar='batch_size',\n",
    "                    help='Size of batch)')\n",
    "parser.add_argument('--test_batch_size', type=int, default=128, metavar='batch_size',\n",
    "                    help='Size of batch)')\n",
    "parser.add_argument('--epochs', type=int, default=250, metavar='N',\n",
    "                    help='number of episode to train ')\n",
    "parser.add_argument('--optim', type=str, default=\"sgd\",\n",
    "                    choices=['sgd', 'adam'],\n",
    "                    help='Optimizer, [sgd, adam]')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                    help='learning rate (default: 0.001, 0.1 if using sgd)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum (default: 0.9)')\n",
    "parser.add_argument('--scheduler', type=str, default='cos', metavar='N',\n",
    "                    choices=['cos', 'step'],\n",
    "                    help='Scheduler to use, [cos, step]')\n",
    "parser.add_argument('--no_cuda', type=bool, default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--eval', type=bool,  default=False,\n",
    "                    help='evaluate the model')\n",
    "parser.add_argument('--num_points', type=int, default=1024,\n",
    "                    help='num of points to use')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='initial dropout rate')\n",
    "parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',\n",
    "                    help='Dimension of embeddings')\n",
    "parser.add_argument('--k', type=int, default=20, metavar='N',\n",
    "                    help='Num of nearest neighbors to use')\n",
    "parser.add_argument('--model_path', type=str, default='', metavar='N',\n",
    "                    help='Pretrained model path')\n",
    "\n",
    "parser.add_argument('--aug', type=str, default='default', metavar='N',\n",
    "                    choices=['default', 'MN40'])\n",
    "parser.add_argument(\"--kermix\", type=bool, default= False)    \n",
    "parser.add_argument(\"--manimix\", type=bool, default=False) \n",
    "parser.add_argument('--sigma', type=float, default=0.3) \n",
    "parser.add_argument('--beta', type=float, default=5.)  \n",
    "parser.add_argument('--no_saliency', action='store_true')\n",
    "parser.add_argument('--smoothing_k', type=int, default=20) \n",
    "parser.add_argument('--temperature', type=float, default=2)\n",
    "parser.add_argument('--temperature2', type=float, default=1)  \n",
    "parser.add_argument('--sample_ver', type=int, default=3) \n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "num_class = 15\n",
    "\n",
    "train_loader = DataLoader(ScanObjectNN(partition='test', num_points=args.num_points, aug=args.aug, ver=\"easy\"), num_workers=4,\n",
    "                                batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# model = DGCNN(args, num_class).to(device)\n",
    "# model =  nn.DataParallel(model)\n",
    "# model.load_state_dict(torch.load(\"outputs/SONN_EASY_base/models/model.t7\"))\n",
    "# model = model.module\n",
    "# model.eval()\n",
    "\n",
    "# model_mix = DGCNN(args, num_class).to(device)\n",
    "# model_mix =  nn.DataParallel(model_mix)\n",
    "# model_mix.load_state_dict(torch.load(\"outputs/basemixup_dgcnn_SONNEASY/models/model.t7\"))\n",
    "# model_mix = model_mix.module\n",
    "# model_mix.eval()\n",
    "\n",
    "model_our = DGCNN(args, num_class).to(device)\n",
    "model_our =  nn.DataParallel(model_our)\n",
    "model_our.load_state_dict(torch.load(\"outputs/sample_ver3_dgcnn_SONN_EASY_0.3_beta0.2/models/model.t7\"))\n",
    "\n",
    "\n",
    "\n",
    "model_our = model_our.module\n",
    "model_our.eval()\n",
    "\n",
    "\n",
    "\n",
    "pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69528794-66d9-4b9f-8bb4-817483eb10bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cls.model import DGCNN\n",
    "model_RS = DGCNN(args, num_class).to(device)\n",
    "model_RS =  nn.DataParallel(model_RS)\n",
    "model_RS = model_RS.module\n",
    "model_RS.eval()\n",
    "\n",
    "model_RS.load_state_dict(torch.load(\"../../RSMix/dgcnn_rsmix/checkpoints/baseRSmix_rotjit_dgcnn_SONN_EASY/models/model.t7\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a858c53e-e9c5-4f10-b952-0e07f531d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8520, device='cuda:0')\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# gaussian\n",
    "def gaussian(data, sigma):\n",
    "    return data + torch.normal(0, sigma, data.shape).to(data.device)\n",
    "\n",
    "# for i  in range(100):\n",
    "count = 0\n",
    "correct = 0\n",
    "correct_RS = 0\n",
    "correct_our = 0\n",
    "correct_mix = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    count+= batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_data = gaussian(data, 0.01)\n",
    "#         logits1, _ = model(new_data.permute(0,2,1), mixup=False)\n",
    "#         correct += (logits1.argmax(-1)==label).sum()\n",
    "        \n",
    "#         logits2,_ = model_mix(new_data.permute(0,2,1))\n",
    "#         correct_mix += (logits2.argmax(-1)==label).sum()\n",
    "        \n",
    "#         logit3 = model_RS(new_data.permute(0,2,1))\n",
    "#         correct_RS += (logit3.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit4,_ = model_our(new_data.permute(0,2,1))\n",
    "        correct_our += (logit4.argmax(-1)==label).sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     logits, _, temp = model(data.permute(0,2,1), label, mixup=True, saliency=saliency, get_mix=True)\n",
    "    # break\n",
    "# print(correct/count)\n",
    "# print(correct_mix/count)\n",
    "# print(correct_RS/count)\n",
    "print(correct_our/count)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f1e71-026b-474b-944d-731e04d13c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotation\n",
    "def rotate(data, axis=\"x\"):\n",
    "    if axis ==\"x\":\n",
    "        idx=[1,2]\n",
    "    elif axis ==\"y\":\n",
    "        idx=[0,2]\n",
    "    elif axis==\"z\":\n",
    "        idx=[0,1]\n",
    "        \n",
    "    theta = np.pi\n",
    "    rotation_matrix = np.array([[-1, 0],[0, -1]]) \n",
    "    data[:,:,idx] = data[:,:,idx] @ torch.tensor(rotation_matrix, dtype=torch.float).to(data.device)\n",
    "    return data\n",
    "\n",
    "# for i  in range(100):\n",
    "count = 0\n",
    "correct = 0\n",
    "correct_RS = 0\n",
    "correct_our = 0\n",
    "correct_mix = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    count+= batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_data = rotate(data, axis=\"z\")\n",
    "#         logits1, _ = model(new_data.permute(0,2,1), mixup=False)\n",
    "#         correct += (logits1.argmax(-1)==label).sum()\n",
    "        \n",
    "#         logits2,_ = model_mix(new_data.permute(0,2,1))\n",
    "#         correct_mix += (logits2.argmax(-1)==label).sum()\n",
    "        \n",
    "#         logit3 = model_RS(new_data.permute(0,2,1))\n",
    "#         correct_RS += (logit3.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit4,_ = model_our(new_data.permute(0,2,1))\n",
    "        correct_our += (logit4.argmax(-1)==label).sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     logits, _, temp = model(data.permute(0,2,1), label, mixup=True, saliency=saliency, get_mix=True)\n",
    "    # break\n",
    "# print(correct/count)\n",
    "# print(correct_mix/count)\n",
    "# print(correct_RS/count)\n",
    "print(correct_our/count)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "230d4f88-2835-4aed-82de-5208e0042a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7504, device='cuda:0')\n",
      "tensor(0.7487, device='cuda:0')\n",
      "tensor(0.7315, device='cuda:0')\n",
      "tensor(0.7883, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def dropout(data, p=0.75):\n",
    "    num_p = int(1024 *p)\n",
    "    idx = torch.randperm(1024)[:num_p]\n",
    "     \n",
    "    return data[:, idx, :]\n",
    "\n",
    "# for i  in range(100):\n",
    "count = 0\n",
    "correct = 0\n",
    "correct_RS = 0\n",
    "correct_our = 0\n",
    "correct_mix = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    count+= batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_data = dropout(data, p=0.5)\n",
    "        logits1, _ = model(new_data.permute(0,2,1), mixup=False)\n",
    "        correct += (logits1.argmax(-1)==label).sum()\n",
    "        \n",
    "        logits2,_ = model_mix(new_data.permute(0,2,1))\n",
    "        correct_mix += (logits2.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit3 = model_RS(new_data.permute(0,2,1))\n",
    "        correct_RS += (logit3.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit4,_ = model_our(new_data.permute(0,2,1))\n",
    "        correct_our += (logit4.argmax(-1)==label).sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     logits, _, temp = model(data.permute(0,2,1), label, mixup=True, saliency=saliency, get_mix=True)\n",
    "    # break\n",
    "print(correct/count)\n",
    "print(correct_mix/count)\n",
    "print(correct_RS/count)\n",
    "print(correct_our/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61ccfd2b-6e05-488d-9356-cd5b3ebcf210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7298, device='cuda:0')\n",
      "tensor(0.7298, device='cuda:0')\n",
      "tensor(0.7453, device='cuda:0')\n",
      "tensor(0.7522, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#scale\n",
    "def resize(data, s=2):\n",
    "    return data*s\n",
    "\n",
    "# for i  in range(100):\n",
    "count = 0\n",
    "correct = 0\n",
    "correct_RS = 0\n",
    "correct_our = 0\n",
    "correct_mix = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    count+= batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_data = resize(data, s=0.6)\n",
    "        logits1, _ = model(new_data.permute(0,2,1), mixup=False)\n",
    "        correct += (logits1.argmax(-1)==label).sum()\n",
    "        \n",
    "        logits2,_ = model_mix(new_data.permute(0,2,1))\n",
    "        correct_mix += (logits2.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit3 = model_RS(new_data.permute(0,2,1))\n",
    "        correct_RS += (logit3.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit4,_ = model_our(new_data.permute(0,2,1))\n",
    "        correct_our += (logit4.argmax(-1)==label).sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     logits, _, temp = model(data.permute(0,2,1), label, mixup=True, saliency=saliency, get_mix=True)\n",
    "    # break\n",
    "print(correct/count)\n",
    "print(correct_mix/count)\n",
    "print(correct_RS/count)\n",
    "print(correct_our/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33b1ce40-2585-495b-9ee6-0b53d5242171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7694, device='cuda:0')\n",
      "tensor(0.7711, device='cuda:0')\n",
      "tensor(0.7745, device='cuda:0')\n",
      "tensor(0.7935, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#scale\n",
    "def local_drop(data, num_point=100):\n",
    "    k=1024-num_point\n",
    "\n",
    "    idx = torch.randperm(1024)[0]\n",
    "    cen = data[:,idx]\n",
    "\n",
    "    sub = data - cen[:,None,:]\n",
    "    dist = (sub**2).sum(-1)\n",
    "    idx = dist.topk(k)[1]\n",
    "\n",
    "    data_new = torch.zeros(data[:,:k,:].shape).to(data.device)\n",
    "    for i in range(batch_size):\n",
    "        data_new[i] = data[i,idx[i],:]\n",
    "    \n",
    "    return data_new\n",
    "\n",
    "# for i  in range(100):\n",
    "count = 0\n",
    "correct = 0\n",
    "correct_RS = 0\n",
    "correct_our = 0\n",
    "correct_mix = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data, label = data.to(device), label.to(device).squeeze()\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    count+= batch_size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_data = local_drop(data, num_point=256)\n",
    "        logits1, _ = model(new_data.permute(0,2,1), mixup=False)\n",
    "        correct += (logits1.argmax(-1)==label).sum()\n",
    "        \n",
    "        logits2,_ = model_mix(new_data.permute(0,2,1))\n",
    "        correct_mix += (logits2.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit3 = model_RS(new_data.permute(0,2,1))\n",
    "        correct_RS += (logit3.argmax(-1)==label).sum()\n",
    "        \n",
    "        logit4,_ = model_our(new_data.permute(0,2,1))\n",
    "        correct_our += (logit4.argmax(-1)==label).sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     logits, _, temp = model(data.permute(0,2,1), label, mixup=True, saliency=saliency, get_mix=True)\n",
    "    # break\n",
    "print(correct/count)\n",
    "print(correct_mix/count)\n",
    "print(correct_RS/count)\n",
    "print(correct_our/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38e5890c-8078-4afd-8895-f8b2b8292f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c020cb8-3611-4176-b40d-092a6b6171b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
