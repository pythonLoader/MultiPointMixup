{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from SageMix import SageMix\n",
    "from data import ModelNet40, ScanObjectNN\n",
    "from model import PointNet, DGCNN\n",
    "from util import cal_loss, cal_loss_mix, IOStream\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "# import io\n",
    "\n",
    "import torch\n",
    "from emd_ import emd_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SageMix:\n",
    "    def __init__(self, args, num_class=40):\n",
    "        self.num_class = num_class\n",
    "        self.EMD = emd_module.emdModule()\n",
    "        self.sigma = args.sigma\n",
    "        self.beta = torch.distributions.beta.Beta(torch.tensor([args.theta]), torch.tensor([args.theta]))\n",
    "    \n",
    "    def mix(self, xyz, label, saliency=None, n_mix=4, theta=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xyz (B,N,3)\n",
    "            label (B)\n",
    "            saliency (B,N): Defaults to None.\n",
    "        \"\"\"        \n",
    "        # label_ori = label.clone()\n",
    "        # print(xyz.shape)\n",
    "        B, N, _ = xyz.shape\n",
    "        # print(\"saliency based\", saliency_based)\n",
    "        # mapping = self.find_optimal_mapping(xyz, saliency)\n",
    "        # return 0\n",
    "        # print(mapping)\n",
    "        # return 0\n",
    "        # print(xyz.shape)\n",
    "        # idxs = mapping[:,1].to(torch.int64) #torch.randperm(B)\n",
    "        idxs = torch.stack([torch.randperm(B) for _ in range(n_mix)])\n",
    "        # idxs = torch.argsort(torch.rand(B, n_clouds))\n",
    "\n",
    "        xyzs = torch.zeros((n_mix, B, N, 3)).cuda()\n",
    "        for i in range(n_mix):\n",
    "            if i == 0: xyzs[i] = xyz\n",
    "            else:\n",
    "                xyzs[i] = xyz[idxs[i]]\n",
    "\n",
    "\n",
    "        all_xyz = torch.zeros((n_mix, B, N, 3)).cuda()\n",
    "        all_xyz[0] = xyzs[0]\n",
    "\n",
    "        all_saliency = torch.zeros((n_mix, B, N)).cuda()\n",
    "        all_saliency[0] = saliency\n",
    "        for i in range(1, n_mix):\n",
    "            _, ass = self.EMD(xyzs[0], xyzs[i], 0.005, 500)\n",
    "\n",
    "            xyz_new = torch.zeros_like(xyzs[i]).cuda()\n",
    "            saliency_new = torch.zeros_like(saliency).cuda()\n",
    "            \n",
    "            # print(ass,ass.shape)\n",
    "            for j in range(B):\n",
    "                # print(\"ass j\", ass[j])\n",
    "                # print(\"ass j shape\", ass[j].shape)\n",
    "                # print(\"xyzs shape\", xyzs.shape)\n",
    "                # print(\"xyzs i shape\", xyzs[i].shape)\n",
    "                all_xyz[i][j] = xyzs[i][j][ass[j]]\n",
    "                all_saliency[i][j] = saliency[idxs[i]][j][ass[j]]\n",
    "\n",
    "                # xyz_new[i] = xyzs[j][ass[j]]\n",
    "                # saliency_new[j] = saliency[idxs[j]][j][ass[j]]\n",
    "            \n",
    "            # all_xyz[i] = xyz_new\n",
    "            # all_saliency[i] = saliency_new\n",
    "        # print(\"permuted saliency\", saliency[1])\n",
    "\n",
    "        anchors = torch.zeros(n_mix, B, 3).cuda()\n",
    "\n",
    "        saliency = saliency/saliency.sum(-1, keepdim=True)\n",
    "        anc_idx = torch.randint(0, 1024, (B,1)).cuda()\n",
    "        # anc_idx = torch.multinomial(saliency, 1, replacement=True)\n",
    "        anchor_ori = all_xyz[0][torch.arange(B), anc_idx[:,0]]\n",
    "        anchors[0] = anchor_ori\n",
    "        # # print(\"anchor shape\", anchor_ori.shape)\n",
    "\n",
    "        anc_idx_new = 0\n",
    "        perm_saliency_new = 0\n",
    "        # ker_weight_fix = 0\n",
    "        for i in range(1, n_mix):\n",
    "            dists = []\n",
    "            for j in range(0,i):\n",
    "                # print(\"all_xyz\", all_xyz[i])\n",
    "                # print(\"anchors\", anchors)\n",
    "                sub = all_xyz[i] - anchors[j][:, None, :]\n",
    "                # subs.append(sub)\n",
    "                dist = ((sub) ** 2).sum(2).sqrt()\n",
    "                dists.append(dist)\n",
    "                # print(dist.shape)\n",
    "            dist = torch.stack(dists).sum(dim=0)\n",
    "            \n",
    "            perm_saliency_new = all_saliency[i] * dist\n",
    "            perm_saliency_new = perm_saliency_new/perm_saliency_new.sum(-1, keepdim=True)\n",
    "\n",
    "\n",
    "        #     ## try to fix this at 0\n",
    "            # anc_idx_new = torch.multinomial(perm_saliency_new, 1, replacement=True)\n",
    "            anc_idx_new = torch.randint(0, 1024, (B,1)).cuda()\n",
    "            anchor_perm_new = all_xyz[i][torch.arange(B),anc_idx_new[:,0]]\n",
    "            anchors[i] = anchor_perm_new\n",
    "            # sub = perm_new - anchor_ori[:,None,:]\n",
    "        #     # dist = ((sub) ** 2).sum(2).sqrt()\n",
    "        #     # perm_saliency = perm_saliency * dist\n",
    "        #     # perm_saliency = perm_saliency/perm_saliency.sum(-1, keepdim=True)\n",
    "        # # alpha = self.dirichlet.sample((B,)).cuda()\n",
    "        pi = torch.distributions.dirichlet.Dirichlet(torch.tensor([theta for i in range(n_mix)])).sample((B,)).cuda()\n",
    "        # # print(\"pi shape\", pi.shape)\n",
    "        # # print(\"pi sum\", pi.sum(1))\n",
    "        \n",
    "\n",
    "        kerns = torch.zeros(n_mix, B, N).cuda()\n",
    "        weights = torch.zeros(n_mix, B, N).cuda()\n",
    "        weights_copy = []\n",
    "        for i in range(n_mix):\n",
    "            sub_ori = all_xyz[i] - anchors[i][:,None,:]\n",
    "            sub_ori = ((sub_ori) ** 2).sum(2).sqrt()\n",
    "        #     #Eq.(6) for first sample\n",
    "            ker_weight_ori = torch.exp(-0.5 * (sub_ori ** 2) / (self.sigma ** 2))  #(M,N)\n",
    "            kerns[i] = ker_weight_ori\n",
    "        #     # print(\"kern weight ori\", ker_weight_ori.shape)\n",
    "\n",
    "            weights[i] = ker_weight_ori * pi[:,i][:,None]\n",
    "            weights_copy.append(weights[i][...,None])\n",
    "\n",
    "            # ker_weight_fix = ker_weight_ori\n",
    "\n",
    "\n",
    "        # # weight = (torch.cat([weight_ori[...,None],weight_perm[...,None]],-1)) + 1e-16\n",
    "        weight = (torch.cat(weights_copy,-1)) + 1e-16\n",
    "        weight = weight/weight.sum(-1)[...,None]\n",
    "\n",
    "        weight_old = weight.clone()\n",
    "        x = torch.zeros((B, N, 3)).cuda()\n",
    "\n",
    "        for i in range(n_mix):\n",
    "            x += weight[:, :, i:i+1] * all_xyz[i]\n",
    "        target = weight.sum(1)\n",
    "        target = target / target.sum(-1, keepdim=True)\n",
    "\n",
    "        label_one_hots = torch.zeros(n_mix, B, self.num_class).cuda()\n",
    "        label_onehot = torch.zeros(B, self.num_class).cuda().scatter(1, label.view(-1, 1), 1)\n",
    "        label_one_hots[0] = label_onehot\n",
    "        # print(\"label_onehot shape\", label_onehot.shape)\n",
    "\n",
    "        label = torch.zeros(B, self.num_class).cuda()\n",
    "        label += label_one_hots[0] * target[:, 0, None]\n",
    "        \n",
    "        for i in range(1, n_mix):\n",
    "            label_perm_onehot = label_onehot[idxs[i]]\n",
    "            label += label_perm_onehot * target[:, i, None]\n",
    "        \n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(z, dist_type='l2'):\n",
    "    '''Return distance matrix between vectors'''\n",
    "    with torch.no_grad():\n",
    "        diff = z.unsqueeze(1) - z.unsqueeze(0)\n",
    "        if dist_type[:2] == 'l2':\n",
    "            A_dist = (diff**2).sum(-1)\n",
    "            if dist_type == 'l2':\n",
    "                A_dist = torch.sqrt(A_dist)\n",
    "            elif dist_type == 'l22':\n",
    "                pass\n",
    "        elif dist_type == 'l1':\n",
    "            A_dist = diff.abs().sum(-1)\n",
    "        elif dist_type == 'linf':\n",
    "            A_dist = diff.abs().max(-1)[0]\n",
    "        else:\n",
    "            return None\n",
    "    return A_dist\n",
    "\n",
    "\n",
    "def calc_A_dist(saliency, theta=0.5):\n",
    "    sc = saliency.unsqueeze(1)\n",
    "    # print(\"sc:\",sc.shape)\n",
    "    # z = F.avg_pool1d(sc, kernel_size=8, stride=1)\n",
    "    # print(\"z:\",z.shape)\n",
    "    z = sc\n",
    "    z_reshape = z.reshape(args.batch_size, -1)\n",
    "    # print(\"z_reshape:\",z_reshape.shape)\n",
    "    z_idx_1d = torch.argmax(z_reshape, dim=1)\n",
    "    z_idx_2d = torch.zeros((args.batch_size, 2), device=z.device)\n",
    "    z_idx_2d[:, 0] = z_idx_1d // z.shape[-1]\n",
    "    z_idx_2d[:, 1] = z_idx_1d % z.shape[-1]\n",
    "    # print(\"z_idx_2d:\",z_idx_2d)\n",
    "    A_dist = distance(z_idx_2d, dist_type='l1')\n",
    "    # print(\"A_dist:\", A_dist)\n",
    "\n",
    "    n_input = saliency.shape[0]\n",
    "    \n",
    "    A_base = torch.eye(n_input, device=out.device)\n",
    "\n",
    "    A_dist = A_dist / torch.sum(A_dist) * n_input\n",
    "    m_omega = torch.distributions.beta.Beta(theta, theta).sample()\n",
    "    A = (1 - m_omega) * A_base + m_omega * A_dist\n",
    "    # print(\"A\", A)\n",
    "    return A\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7e43317eb3113a636e59ebf4e4d52ed79ac7360830f592e9d05ab9479dd90e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
