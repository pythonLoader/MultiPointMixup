{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from SageMix import SageMix\n",
    "from data import ModelNet40, ScanObjectNN\n",
    "from model import PointNet, DGCNN\n",
    "from util import cal_loss, cal_loss_mix, IOStream\n",
    "import gco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(batch_size=3, data='MN40', dropout=0.5, emb_dims=1024, epochs=50, eval=False, exp_name='SageMix', k=20, lr=0.0001, model='pointnet', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, sigma=-1, test_batch_size=16, theta=0.2, use_sgd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1024\n",
    "dataset = ModelNet40(partition='train', num_points=num_points)\n",
    "batch_size=args.batch_size\n",
    "# print(dataset)\n",
    "# dataset = dataset[:100]\n",
    "# batch_size = len(dataset)\n",
    "# print('args.batch_size:',batch_size)\n",
    "test_batch_size = args.test_batch_size\n",
    "train_loader = DataLoader(dataset, num_workers=8,\n",
    "                        batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(ModelNet40(partition='test', num_points=num_points), num_workers=8,\n",
    "                        batch_size=test_batch_size, shuffle=True, drop_last=False)\n",
    "num_class=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from emd_ import emd_module\n",
    "\n",
    "class SageMix:\n",
    "    def __init__(self, args, device, num_class=40):\n",
    "        self.num_class = num_class\n",
    "        self.EMD = emd_module.emdModule()\n",
    "        self.sigma = args.sigma\n",
    "        self.beta = torch.distributions.beta.Beta(torch.tensor([args.theta]), torch.tensor([args.theta]))\n",
    "        self.device = device\n",
    "\n",
    "    def mix(self, xyz, label, saliency=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xyz (B,N,3)\n",
    "            label (B)\n",
    "            saliency (B,N): Defaults to None.\n",
    "        \"\"\"        \n",
    "        B, N, _ = xyz.shape\n",
    "        # print(xyz.shape)\n",
    "        idxs = torch.randperm(B)\n",
    "\n",
    "        \n",
    "        #Optimal assignment in Eq.(3)\n",
    "        # perm = xyz[idxs]\n",
    "        dist_mat = torch.empty(B, B, 1024)\n",
    "        ass_mat = torch.empty(B,B,1024)\n",
    "        dist_mat = dist_mat.to(self.device)\n",
    "        \n",
    "        # print(\"Starting to compute optimal assignment (Heuristic-1)\")\n",
    "        for idx,point in enumerate(xyz):\n",
    "            # perm = torch.tensor([point for x in range(B))\n",
    "            # print(point.shape)\n",
    "            perm = point.repeat(B,1)\n",
    "            # print(perm.shape)\n",
    "\n",
    "            perm  = perm.reshape(perm.shape[0]//1024,1024,3)\n",
    "            \n",
    "            dist, ass = self.EMD(xyz, perm, 0.005, 500) # mapping\n",
    "                 # 32,1024\n",
    "            dist_mat[idx] = dist\n",
    "            ass_mat[idx] = ass\n",
    "\n",
    "            # print('dist:',dist.shape)\n",
    "            # if idx % 10 == 0:\n",
    "            #     print(\"Now doing\", idx)\n",
    "        \n",
    "        # print(dist_mat.shape)\n",
    "        dist_mat = torch.norm(dist_mat,dim=2)\n",
    "        avg_alignment_dist = torch.mean(dist_mat,dim=0)\n",
    "        # print(avg_alignment_dist.shape)\n",
    "        # print('avg_alignment:',avg_alignment_dist)\n",
    "        # print('mean:',torch.mean(avg_alignment_dist))\n",
    "        # print('min:',torch.min(avg_alignment_dist))\n",
    "        # print('max:',torch.max(avg_alignment_dist))\n",
    "        # print(torch.min(avg_alignment_dist))\n",
    "        # print(torch.argmin(avg_alignment_dist).item())\n",
    "\n",
    "        idx = torch.argmin(avg_alignment_dist).item()\n",
    "        # dist_mat = dist_mat.fill_diagonal_(100000.0)\n",
    "    \n",
    "        \n",
    "        # i,j = divmod(torch.argmin(dist_mat).item(),dist_mat.shape[1])\n",
    "        ass = ass_mat[idx]\n",
    "        \n",
    "        ass = ass.long()\n",
    "\n",
    "        # sz = ass.size(0)\n",
    "        perm_new = torch.zeros_like(perm).to(self.device)\n",
    "        # print('perm:',perm)\n",
    "        # print(perm_new.shape)\n",
    "        perm = xyz.clone()\n",
    "        # print(\"idx:\",idx)\n",
    "        for i in range(B):\n",
    "            # print('i:',i)\n",
    "            perm_new[i] = perm[i][ass[i]]\n",
    "            # print('perm_i',perm[i])\n",
    "            # print('perm_new_i',perm_new[i])\n",
    "\n",
    "        # print('perm_new',perm_new)\n",
    "\n",
    "        return ass,perm_new,dist_mat\n",
    "\n",
    "        # print(\"Done with compute optimal assignment (Heuristic-1)\")\n",
    "        # print(ass.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(z, dist_type='l2'):\n",
    "    '''Return distance matrix between vectors'''\n",
    "    with torch.no_grad():\n",
    "        diff = z.unsqueeze(1) - z.unsqueeze(0)\n",
    "        if dist_type[:2] == 'l2':\n",
    "            A_dist = (diff**2).sum(-1)\n",
    "            if dist_type == 'l2':\n",
    "                A_dist = torch.sqrt(A_dist)\n",
    "            elif dist_type == 'l22':\n",
    "                pass\n",
    "        elif dist_type == 'l1':\n",
    "            A_dist = diff.abs().sum(-1)\n",
    "        elif dist_type == 'linf':\n",
    "            A_dist = diff.abs().max(-1)[0]\n",
    "        else:\n",
    "            return None\n",
    "    return A_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.4142, 1.4142],\n",
       "        [1.4142, 0.0000, 1.4142],\n",
       "        [1.4142, 1.4142, 0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.tensor([[1,0,0],[0,1,0], [0,0,1]])\n",
    "\n",
    "# distance(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from match import get_onehot_matrix, mix_input\n",
    "from math import ceil\n",
    "\n",
    "import importlib\n",
    "import match\n",
    "importlib.reload(match)\n",
    "from match import get_onehot_matrix, mix_input\n",
    "\n",
    "importlib.reload(gco)\n",
    "# from match import get_onehot_matrix, mix_input\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def mixup_process(out, target_reweighted, args=None, sc=None, A_dist=None):\n",
    "    m_block_num = args.m_block_num\n",
    "    m_part = args.m_part\n",
    "\n",
    "    # batch_size = out.shape[0]\n",
    "    # width = out.shape[-1]\n",
    "\n",
    "    if A_dist is None:\n",
    "        A_dist = torch.eye(batch_size, device=out.device)\n",
    "\n",
    "    if m_block_num == -1:\n",
    "        m_block_num = 2**np.random.randint(1, 5)\n",
    "\n",
    "    \n",
    "    # block_size = width // m_block_num\n",
    "    block_size = 8\n",
    "    # print(\"block size:\",block_size)\n",
    "    # print(\"sc:\",sc.shape) # 8,1024\n",
    "    # sc = sc.unsqueeze(1)\n",
    "    # sc = F.avg_pool1d(sc, block_size)\n",
    "\n",
    "\n",
    "    out_list = []\n",
    "    target_list = []\n",
    "\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sc_part = sc\n",
    "        A_dist_part = A_dist\n",
    "\n",
    "        n_input = sc.shape[0]\n",
    "        # print(\"n_input\", n_input)\n",
    "        # print(\"scpart rehspae\", sc_part.reshape(n_input, -1).shape)\n",
    "        # print(\"sc_part reshape sum\", sc_part.sum(1).shape)\n",
    "        # print(\"total shape\", sc_part.reshape(n_input, -1).sum(1).reshape(n_input, 1, 1).shape)\n",
    "\n",
    "        ## ORIGINAL CODE\n",
    "        # sc_norm = sc_part / sc_part.reshape(n_input, -1).sum(1).reshape(n_input, 1, 1)\n",
    "\n",
    "        ## NEW CODE\n",
    "        # print(\"sc part shape\", sc_part.shape)\n",
    "        # print(\"sc part sum\", sc_part.sum(1).shape)\n",
    "        # sc_norm = sc_part / sc_part.sum(1).reshape(n_input, 1, 1)\n",
    "        sc_norm = sc/torch.sum(sc, dim=1).view(-1,1)\n",
    "        # print(\"sc_norm\", sc_norm.shape)\n",
    "        cost_matrix = -sc_norm\n",
    "        # print(cost_matrix.shape)\n",
    "\n",
    "        A_base = torch.eye(n_input, device=out.device)\n",
    "        A_dist_part = A_dist_part / torch.sum(A_dist_part) * n_input\n",
    "        A = (1 - args.m_omega) * A_base + args.m_omega * A_dist_part\n",
    "        print(\"A:\",A)\n",
    "\n",
    "        # print(\"new A shape:\",A.shape)\n",
    "        # Return a batch(partitioned) of mixup labeling\n",
    "        # mask_onehot = get_onehot_matrix(cost_matrix.detach(),\n",
    "        #                                 A,\n",
    "        #                                 n_output=n_input,\n",
    "        #                                 beta=args.m_beta,\n",
    "        #                                 gamma=args.m_gamma,\n",
    "        #                                 eta=args.m_eta,\n",
    "        #                                 mixup_alpha=args.mixup_alpha,\n",
    "        #                                 thres=args.m_thres,\n",
    "        #                                 thres_type=args.m_thres_type,\n",
    "        #                                 set_resolve=args.set_resolve,\n",
    "        #                                 niter=args.m_niter,\n",
    "        #                                 device='cuda')\n",
    "        mask_onehot = get_onehot_matrix(cost_matrix.detach(),\n",
    "                                        A,\n",
    "                                        n_output=1,\n",
    "                                        beta=args.m_beta,\n",
    "                                        gamma=args.m_gamma,\n",
    "                                        eta=args.m_eta,\n",
    "                                        mixup_alpha=args.mixup_alpha,\n",
    "                                        thres=args.m_thres,\n",
    "                                        thres_type=args.m_thres_type,\n",
    "                                        set_resolve=args.set_resolve,\n",
    "                                        niter=args.m_niter,\n",
    "                                        device='cuda')\n",
    "        \n",
    "    print('mask onehot shape:',mask_onehot.shape)\n",
    "    # print(mask_onehot)\n",
    "    # Generate image and corrsponding soft target\n",
    "    output_part, target_part = mix_input(mask_onehot, out,\n",
    "                                             target_reweighted)\n",
    "\n",
    "    out_list = output_part\n",
    "    print(out_list)\n",
    "    target_list = target_part\n",
    "    print(target_list)\n",
    "    # out_list.append(output_part)\n",
    "    # target_list.append(target_part)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Partition a batch\n",
    "    # for i in range(ceil(batch_size / m_part)):\n",
    "    #     with torch.no_grad():\n",
    "    #         sc_part = sc[i * m_part:(i + 1) * m_part]\n",
    "    #         A_dist_part = A_dist[i * m_part:(i + 1) * m_part, i * m_part:(i + 1) * m_part]\n",
    "\n",
    "    #         n_input = sc_part.shape[0]\n",
    "    #         sc_norm = sc_part / sc_part.reshape(n_input, -1).sum(1).reshape(n_input, 1, 1)\n",
    "    #         cost_matrix = -sc_norm\n",
    "\n",
    "    #         A_base = torch.eye(n_input, device=out.device)\n",
    "    #         A_dist_part = A_dist_part / torch.sum(A_dist_part) * n_input\n",
    "    #         A = (1 - args.m_omega) * A_base + args.m_omega * A_dist_part\n",
    "\n",
    "    #         # Return a batch(partitioned) of mixup labeling\n",
    "    #         mask_onehot = get_onehot_matrix(cost_matrix.detach(),\n",
    "    #                                         A,\n",
    "    #                                         n_output=n_input,\n",
    "    #                                         beta=args.m_beta,\n",
    "    #                                         gamma=args.m_gamma,\n",
    "    #                                         eta=args.m_eta,\n",
    "    #                                         mixup_alpha=args.mixup_alpha,\n",
    "    #                                         thres=args.m_thres,\n",
    "    #                                         thres_type=args.m_thres_type,\n",
    "    #                                         set_resolve=args.set_resolve,\n",
    "    #                                         niter=args.m_niter,\n",
    "    #                                         device='cuda')\n",
    "\n",
    "    #     # Generate image and corrsponding soft target\n",
    "    #     output_part, target_part = mix_input(mask_onehot, out[i * m_part:(i + 1) * m_part],\n",
    "    #                                          target_reweighted[i * m_part:(i + 1) * m_part])\n",
    "\n",
    "    #     out_list.append(output_part)\n",
    "    #     target_list.append(target_part)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     out = torch.cat(out_list, dim=0)\n",
    "    #     target_reweighted = torch.cat(target_list, dim=0)\n",
    "\n",
    "    return output_part, target_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args2 = {'arch': 'preactresnet18', 'batch_size': 100, \n",
    "         'clean_lam': 1.0, 'comix': True, \n",
    "         'data_dir': './data/cifar100/', 'dataset': 'cifar100', \n",
    "         'decay': 0.0001, 'dropout': False, 'epochs': 300, \n",
    "         'evaluate': True, 'gammas': [0.1, 0.1], 'initial_channels': 64, \n",
    "         'labels_per_class': 500, 'learning_rate': 0.2, \n",
    "         'log_off': True, 'm_beta': 0.32, \n",
    "         'm_block_num': 4, 'm_eta': 0.05, \n",
    "         'm_gamma': 1.0, 'm_niter': 4, 'm_omega': 0.001, \n",
    "         'm_part': 20, 'm_thres': 0.83, \n",
    "         'm_thres_type': 'hard', \n",
    "         'mixup_alpha': 2.0, \n",
    "         'momentum': 0.9, 'ngpu': 1, \n",
    "         'parallel': False, 'print_freq': 100, \n",
    "         'resume': './checkpoint/cifar100_preactresnet18_eph300_comixup/checkpoint.pth.tar', \n",
    "         'root_dir': 'experiments', 'schedule': [100, 200], 'seed': 0, \n",
    "         'set_resolve': True, 'start_epoch': 0, 'tag': '', \n",
    "         'use_cuda': True, 'valid_labels_per_class': 0, 'workers': 0}\n",
    "\n",
    "args2 = argparse.Namespace(**args2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(args2.m_block_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 8 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0873, -0.0416,  0.3306],\n",
      "         [-0.2527,  0.0031, -0.0017],\n",
      "         [ 0.4310, -0.0219,  0.0915],\n",
      "         ...,\n",
      "         [ 0.2252, -0.0219, -0.2534],\n",
      "         [-0.0662,  0.0031,  0.4442],\n",
      "         [-0.1810, -0.0219,  0.7870]],\n",
      "\n",
      "        [[ 0.5484, -0.0995, -0.9262],\n",
      "         [ 0.4643,  0.0499, -0.0856],\n",
      "         [ 0.2219,  0.4488,  0.9309],\n",
      "         ...,\n",
      "         [ 0.3038,  0.0499, -0.6911],\n",
      "         [-0.0686,  0.0499, -0.1031],\n",
      "         [ 0.2990,  0.0499, -0.3497]],\n",
      "\n",
      "        [[ 0.2852, -0.0534, -0.3134],\n",
      "         [-0.3129,  0.0405,  0.2038],\n",
      "         [ 0.4006,  0.0374, -0.2213],\n",
      "         ...,\n",
      "         [ 0.0184,  0.0915,  0.5804],\n",
      "         [-0.5774, -0.0564, -0.2586],\n",
      "         [ 0.0683, -0.0121, -0.2597]]], device='cuda:0')\n",
      "torch.Size([3, 3, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3280 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024, 3])\n",
      "perm_new torch.Size([3, 1024, 3])\n",
      "target_reweighted torch.Size([3, 40])\n",
      "Namespace(arch='preactresnet18', batch_size=100, clean_lam=1.0, comix=True, data_dir='./data/cifar100/', dataset='cifar100', decay=0.0001, dropout=False, epochs=300, evaluate=True, gammas=[0.1, 0.1], initial_channels=64, labels_per_class=500, learning_rate=0.2, log_off=True, m_beta=0.32, m_block_num=4, m_eta=0.05, m_gamma=1.0, m_niter=4, m_omega=0.001, m_part=20, m_thres=0.83, m_thres_type='hard', mixup_alpha=2.0, momentum=0.9, ngpu=1, parallel=False, print_freq=100, resume='./checkpoint/cifar100_preactresnet18_eph300_comixup/checkpoint.pth.tar', root_dir='experiments', schedule=[100, 200], seed=0, set_resolve=True, start_epoch=0, tag='', use_cuda=True, valid_labels_per_class=0, workers=0)\n",
      "sc torch.Size([3, 1, 1024])\n",
      "A_dist torch.Size([3, 3])\n",
      "A: tensor([[9.9900e-01, 2.9242e-04, 7.5000e-04],\n",
      "        [2.9242e-04, 9.9900e-01, 4.5758e-04],\n",
      "        [7.5000e-04, 4.5758e-04, 9.9900e-01]], device='cuda:0')\n",
      "cost shape inside graphcut multi (1024, 3)\n",
      "shape of labels:  (1024,)\n",
      "penalty shape torch.Size([3, 1, 1])\n",
      "mask onehot shape torch.Size([1, 1024, 3])\n",
      "before penalty\n",
      "penalty is OK\n",
      "cost penalty shape inside graphcut wrapper elif torch.Size([1024, 3])\n",
      "cost add shape torch.Size([1024, 3])\n",
      "cost penalty after concat torch.Size([1024, 6])\n",
      "cost shape inside graphcut multi (1024, 6)\n",
      "shape of labels:  (1024,)\n",
      "mask idx onehot shape inside graphcut wrapper elif torch.Size([1024, 6])\n",
      "penalty shape torch.Size([3, 1, 1])\n",
      "mask onehot shape torch.Size([1, 1024, 3])\n",
      "before penalty\n",
      "penalty is OK\n",
      "cost penalty shape inside graphcut wrapper elif torch.Size([1024, 3])\n",
      "cost add shape torch.Size([1024, 3])\n",
      "cost penalty after concat torch.Size([1024, 6])\n",
      "cost shape inside graphcut multi (1024, 6)\n",
      "shape of labels:  (1024,)\n",
      "mask idx onehot shape inside graphcut wrapper elif torch.Size([1024, 6])\n",
      "penalty shape torch.Size([3, 1, 1])\n",
      "mask onehot shape torch.Size([1, 1024, 3])\n",
      "before penalty\n",
      "penalty is OK\n",
      "mask onehot shape: torch.Size([1, 1024, 3])\n",
      "mask one hot shape inside mix input torch.Size([1, 1024, 3])\n",
      "tensor([[[ 0.0347,  0.0009,  0.3875],\n",
      "         [-0.0651,  0.3973,  0.3144],\n",
      "         [ 0.2421, -0.0138, -0.1250],\n",
      "         ...,\n",
      "         [ 0.1930,  0.0184,  0.0837],\n",
      "         [-0.1329, -0.0484, -0.3389],\n",
      "         [-0.0107,  0.2713,  0.7785]]], device='cuda:0')\n",
      "tensor([[0.4268, 0.0000, 0.4517, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 97\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39m# model.train()\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \n\u001b[1;32m     87\u001b[0m     \u001b[39m# opt.zero_grad()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39m# count += batch_size\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# train_loss += loss.item() * batch_size\u001b[39;00m\n\u001b[1;32m     96\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 97\u001b[0m outstr \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTrain \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, loss: \u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (epoch, train_loss\u001b[39m*\u001b[39;49m\u001b[39m1.0\u001b[39;49m\u001b[39m/\u001b[39;49mcount)\n\u001b[1;32m     98\u001b[0m \u001b[39mprint\u001b[39m(outstr)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = PointNet(args, num_class).to(device)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
    "    \n",
    "\n",
    "sagemix = SageMix(args, device, num_class)\n",
    "criterion = cal_loss_mix\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    ####################\n",
    "    # Train\n",
    "    ####################\n",
    "    train_loss = 0.0\n",
    "    count = 0.0\n",
    "    model.train()\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        print(data)\n",
    "        batch_size = data.size()[0]\n",
    "        \n",
    "        ####################\n",
    "        # generate augmented sample\n",
    "        ####################\n",
    "        model.eval()\n",
    "        print(data.permute(0,2,1).shape)\n",
    "        data_var = Variable(data.permute(0,2,1), requires_grad=True)\n",
    "        logits = model(data_var)\n",
    "        loss = cal_loss(logits, label, smoothing=False)\n",
    "        loss.backward()\n",
    "        opt.zero_grad()\n",
    "        saliency = torch.sqrt(torch.mean(data_var.grad**2,1))\n",
    "        \n",
    "        assignment,perm_new,align_dist = sagemix.mix(data, label, saliency)\n",
    "        print(perm_new.shape)\n",
    "        # data_var2 = Variable(perm_new.permute(0,2,1), requires_grad=True)\n",
    "        \n",
    "        # sc = torch.sqrt(torch.mean(data_var2.grad**2,1))\n",
    "        # print('assignment:',assignment.shape)\n",
    "        # print(assignment[0])\n",
    "        # print('new_permutation',perm_new.shape)\n",
    "        \n",
    "        target_reweighted = F.one_hot(label, num_classes=num_class).float()\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            # print(saliency.shape)\n",
    "            sc = saliency.unsqueeze(1)\n",
    "            # print(\"sc:\",sc.shape)\n",
    "            z = F.avg_pool1d(sc, kernel_size=8, stride=1)\n",
    "            # print(\"z:\",z.shape)\n",
    "            z_reshape = z.reshape(args.batch_size, -1)\n",
    "            # print(\"z_reshape:\",z_reshape.shape)\n",
    "            z_idx_1d = torch.argmax(z_reshape, dim=1)\n",
    "            z_idx_2d = torch.zeros((args.batch_size, 2), device=z.device)\n",
    "            z_idx_2d[:, 0] = z_idx_1d // z.shape[-1]\n",
    "            z_idx_2d[:, 1] = z_idx_1d % z.shape[-1]\n",
    "            A_dist = distance(z_idx_2d, dist_type='l1')\n",
    "            # print(\"A_dist:\",A_dist.shape)\n",
    "            # print(A_dist)\n",
    "\n",
    "        # print(A_dist)\n",
    "        print(\"perm_new\", perm_new.shape)\n",
    "        print(\"target_reweighted\", target_reweighted.shape)\n",
    "        print(args2)\n",
    "        print(\"sc\", sc.shape)\n",
    "        print(\"A_dist\", A_dist.shape)\n",
    "        out, target_reweighted = mixup_process(perm_new,\n",
    "                                                target_reweighted,\n",
    "                                                args=args2,\n",
    "                                                sc=saliency,\n",
    "                                                A_dist=A_dist)\n",
    "        break\n",
    "        # model.train()\n",
    "            \n",
    "        # opt.zero_grad()\n",
    "        # logits = model(data.permute(0,2,1))\n",
    "        # loss = criterion(logits, label)\n",
    "        # loss.backward()\n",
    "        # opt.step()\n",
    "        # preds = logits.max(dim=1)[1]\n",
    "        # count += batch_size\n",
    "        # train_loss += loss.item() * batch_size\n",
    "        \n",
    "    scheduler.step()\n",
    "    outstr = 'Train %d, loss: %.6f' % (epoch, train_loss*1.0/count)\n",
    "    print(outstr)\n",
    "    # io.cprint(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# !pip install open3dfind_alignment_and_mapping\n",
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have \"points\" as your numpy array containing the points you want to plot\n",
    "# points = np.random.rand(100, 3)\n",
    "\n",
    "# point_cloud = o3d.geometry.PointCloud()\n",
    "# point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "points = out.squeeze().cpu().numpy()\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "o3d.io.write_point_cloud(\"my_point_cloud.pcd\", point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out.squeeze().cpu().numpy()\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "for i in range(3):\n",
    "    points = data[i].squeeze().cpu().numpy()\n",
    "\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    o3d.io.write_point_cloud(\"clouds/my_point_cloud_input_{}.pcd\".format(i), point_cloud)\n",
    "\n",
    "points = out.squeeze().cpu().numpy()\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "o3d.io.write_point_cloud(\"clouds/my_point_cloud_output.pcd\", point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Mar  8 2023, 14:00:05) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b486c1e81d32408da1fc5257421bb419818dd94b97c55691de411a2d2d107697"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
