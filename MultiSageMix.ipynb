{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from SageMix import SageMix\n",
    "from data import ModelNet40, ScanObjectNN\n",
    "from model import PointNet, DGCNN\n",
    "from util import cal_loss, cal_loss_mix, IOStream\n",
    "import gco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "args = argparse.Namespace(batch_size=3, data='MN40', dropout=0.5, emb_dims=1024, epochs=50, eval=False, exp_name='SageMix', k=20, lr=0.0001, model='pointnet', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, sigma=-1, test_batch_size=16, theta=0.2, use_sgd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1024\n",
    "dataset = ModelNet40(partition='train', num_points=num_points)\n",
    "batch_size=args.batch_size\n",
    "\n",
    "test_batch_size = args.test_batch_size\n",
    "train_loader = DataLoader(dataset, num_workers=8,\n",
    "                        batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(ModelNet40(partition='test', num_points=num_points), num_workers=8,\n",
    "                        batch_size=test_batch_size, shuffle=True, drop_last=False)\n",
    "num_class=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from emd_ import emd_module\n",
    "\n",
    "class SageMix:\n",
    "    def __init__(self, args, device, num_class=40):\n",
    "        self.num_class = num_class\n",
    "        self.EMD = emd_module.emdModule()\n",
    "        self.sigma = args.sigma\n",
    "        self.beta = torch.distributions.beta.Beta(torch.tensor([args.theta]), torch.tensor([args.theta]))\n",
    "        self.device = device\n",
    "\n",
    "    def mix(self, xyz, label, saliency=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xyz (B,N,3)\n",
    "            label (B)\n",
    "            saliency (B,N): Defaults to None.\n",
    "        \"\"\"        \n",
    "        B, N, _ = xyz.shape\n",
    "        # print(xyz.shape)\n",
    "        idxs = torch.randperm(B)\n",
    "\n",
    "        \n",
    "        #Optimal assignment in Eq.(3)\n",
    "        # perm = xyz[idxs]\n",
    "        dist_mat = torch.empty(B, B, 1024)\n",
    "        ass_mat = torch.empty(B,B,1024)\n",
    "        dist_mat = dist_mat.to(self.device)\n",
    "        \n",
    "        # print(\"Starting to compute optimal assignment (Heuristic-1)\")\n",
    "        for idx,point in enumerate(xyz):\n",
    "            # perm = torch.tensor([point for x in range(B))\n",
    "            # print(point.shape)\n",
    "            perm = point.repeat(B,1)\n",
    "            # print(perm.shape)\n",
    "\n",
    "            perm  = perm.reshape(perm.shape[0]//1024,1024,3)\n",
    "            \n",
    "            dist, ass = self.EMD(xyz, perm, 0.005, 500) # mapping\n",
    "                 # 32,1024\n",
    "            dist_mat[idx] = dist\n",
    "            ass_mat[idx] = ass\n",
    "\n",
    "            # print('dist:',dist.shape)\n",
    "            # if idx % 10 == 0:\n",
    "            #     print(\"Now doing\", idx)\n",
    "        \n",
    "        # print(dist_mat.shape)\n",
    "        dist_mat = torch.norm(dist_mat,dim=2)\n",
    "        avg_alignment_dist = torch.mean(dist_mat,dim=0)\n",
    "        # print(avg_alignment_dist.shape)\n",
    "        # print('avg_alignment:',avg_alignment_dist)\n",
    "        # print('mean:',torch.mean(avg_alignment_dist))\n",
    "        # print('min:',torch.min(avg_alignment_dist))\n",
    "        # print('max:',torch.max(avg_alignment_dist))\n",
    "        # print(torch.min(avg_alignment_dist))\n",
    "        # print(torch.argmin(avg_alignment_dist).item())\n",
    "\n",
    "        idx = torch.argmin(avg_alignment_dist).item()\n",
    "        # dist_mat = dist_mat.fill_diagonal_(100000.0)\n",
    "    \n",
    "        \n",
    "        # i,j = divmod(torch.argmin(dist_mat).item(),dist_mat.shape[1])\n",
    "        ass = ass_mat[idx]\n",
    "        \n",
    "        ass = ass.long()\n",
    "\n",
    "        # sz = ass.size(0)\n",
    "        perm_new = torch.zeros_like(perm).to(self.device)\n",
    "        # print('perm:',perm)\n",
    "        # print(perm_new.shape)\n",
    "        perm = xyz.clone()\n",
    "        # print(\"idx:\",idx)\n",
    "        for i in range(B):\n",
    "            # print('i:',i)\n",
    "            perm_new[i] = perm[i][ass[i]]\n",
    "            # print('perm_i',perm[i])\n",
    "            # print('perm_new_i',perm_new[i])\n",
    "\n",
    "        # print('perm_new',perm_new)\n",
    "\n",
    "        return ass,perm_new,dist_mat\n",
    "\n",
    "        # print(\"Done with compute optimal assignment (Heuristic-1)\")\n",
    "        # print(ass.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = PointNet(args, num_class).to(device)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
    "    \n",
    "\n",
    "sagemix = SageMix(args, device, num_class)\n",
    "criterion = cal_loss_mix\n",
    "\n",
    "\n",
    "best_test_acc = 0\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    ####################\n",
    "    # Train\n",
    "    ####################\n",
    "    train_loss = 0.0\n",
    "    count = 0.0\n",
    "    model.train()\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        print(data)\n",
    "        batch_size = data.size()[0]\n",
    "        \n",
    "        ####################\n",
    "        # generate augmented sample\n",
    "        ####################\n",
    "        model.eval()\n",
    "        print(data.permute(0,2,1).shape)\n",
    "        data_var = Variable(data.permute(0,2,1), requires_grad=True)\n",
    "        logits = model(data_var)\n",
    "        loss = cal_loss(logits, label, smoothing=False)\n",
    "        loss.backward()\n",
    "        opt.zero_grad()\n",
    "        saliency = torch.sqrt(torch.mean(data_var.grad**2,1))\n",
    "        \n",
    "        assignment,perm_new,align_dist = sagemix.mix(data, label, saliency)\n",
    "\n",
    "        # model.train()\n",
    "            \n",
    "        # opt.zero_grad()\n",
    "        # logits = model(data.permute(0,2,1))\n",
    "        # loss = criterion(logits, label)\n",
    "        # loss.backward()\n",
    "        # opt.step()\n",
    "        # preds = logits.max(dim=1)[1]\n",
    "        # count += batch_size\n",
    "        # train_loss += loss.item() * batch_size\n",
    "        \n",
    "    scheduler.step()\n",
    "    outstr = 'Train %d, loss: %.6f' % (epoch, train_loss*1.0/count)\n",
    "    print(outstr)\n",
    "    # io.cprint(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
